{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6g8VdHBne1jz",
    "outputId": "2b8f632a-6a0d-45c1-b201-7d84024916c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.63.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gensim==4.2.0 in /opt/conda/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.7.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (6.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.21.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: Cython in /opt/conda/lib/python3.7/site-packages (0.29.32)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install sklearn\n",
    "!pip install gensim==4.2.0\n",
    "!pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JbkGG-nlmzSI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nm169Kxtd-bV"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import gensim\n",
    "import Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6fZS7S0PvhHh",
    "outputId": "8bf1da1b-1f4f-4d30-88fe-10c928052cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct  7 15:25:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8    16W / 350W |      3MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = json.load(open(r'data/backup/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "data = []\n",
    "d2v = gensim.models.doc2vec.Doc2Vec.load(r'doc2vec.model')\n",
    "\n",
    "for i, record in enumerate(raw):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    proauthors = [i for i in record['authors'] if i < 100]\n",
    "    label = np.zeros(101)\n",
    "    # label[proauthors] = 1.\n",
    "    if len(proauthors) > 0:\n",
    "        label[proauthors] = 1.\n",
    "    else: \n",
    "        label[-1] = 1.\n",
    "    labels.append(label)\n",
    "    \n",
    "    text = [str(i) for i in record['title']]\n",
    "    text.extend([str(i) for i in record['abstract']])\n",
    "    text = d2v.infer_vector(text)\n",
    "    \n",
    "    coauthors = np.zeros(21146)\n",
    "    coauthors[[i-100 for i in [i for i in record['authors'] if i >= 100]]] = 1.\n",
    "    \n",
    "    venue = np.zeros(465)\n",
    "    venue[[record['venue']] if record['venue'] != '' else []] = 1.\n",
    "    \n",
    "    data.append(np.concatenate([text, coauthors, venue], axis=0))\n",
    "    \n",
    "labels = np.stack(labels, axis=0)\n",
    "data = np.stack(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.where(labels[:, -1]==0)\n",
    "data_t = data[ids]\n",
    "labels_t = labels[ids]\n",
    "\n",
    "ids = np.where(labels[:, -1]==1)\n",
    "data_f = data[ids]\n",
    "labels_f = labels[ids]\n",
    "\n",
    "data_t, labels_t = resample(data_t, labels_t, replace=True, n_samples=int(labels_f.shape[0]), random_state=51)\n",
    "\n",
    "data = np.concatenate([data_t, data_f])\n",
    "labels = np.concatenate([labels_t, labels_f])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36666, 21867)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36666, 101)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid, labels_train, labels_valid = train_test_split(data, labels, test_size=0.2, random_state=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(torch.tensor(data_train, dtype=torch.float), torch.tensor(labels_train, dtype=torch.float))\n",
    "valid_set = TensorDataset(torch.tensor(data_valid, dtype=torch.float), torch.tensor(labels_valid, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UqCD9F1lIGGv"
   },
   "outputs": [],
   "source": [
    "class AuthorAttriClf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AuthorAttriClf, self).__init__()\n",
    "        \n",
    "        self.clf_block = nn.Sequential(\n",
    "            nn.Linear(21867, 2048),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 101),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        probs = self.clf_block(input)\n",
    "\n",
    "        return probs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qTd7tZgJO-tz"
   },
   "outputs": [],
   "source": [
    "def train(train_status, model, optim, scheduler, criterion, epoch_size, train_loader, valid_loader):\n",
    "   \n",
    "    for epoch in range(epoch_size):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_labels = torch.Tensor([])\n",
    "        epoch_preds = torch.Tensor([])\n",
    "\n",
    "        train_loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{epoch_size}]\")\n",
    "\n",
    "        for batch, (inputs, labels) in train_loop:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step() \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_preds = torch.cat(((epoch_preds, (outputs.detach().cpu() > 0.5).int())), 0)\n",
    "            epoch_labels = torch.cat((epoch_labels, labels.detach().cpu()), 0)\n",
    "\n",
    "            train_loop.set_postfix_str(\n",
    "                'train_loss={:.5f}'.format(loss.item())\n",
    "            )\n",
    "\n",
    "            if batch == len(train_loader)-1:\n",
    "                epoch_loss /= len(train_loader.dataset)/train_loader.batch_size\n",
    "                train_f1 = f1_score(epoch_labels, epoch_preds, average='samples', zero_division=1)\n",
    "                valid_f1 = validate(model, valid_loader)\n",
    "                train_loop.set_postfix_str(\n",
    "                    'train_loss={:.5f}, train_f1={:.5f}, valid_f1={:.5f}'.format(\n",
    "                        epoch_loss, train_f1, valid_f1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "def validate(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_labels = torch.Tensor([])\n",
    "    valid_preds = torch.Tensor([])\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            valid_preds = torch.cat(((valid_preds, (outputs.detach().cpu() > 0.5).int())), 0)\n",
    "            valid_labels = torch.cat((valid_labels, labels.detach().cpu()), 0)\n",
    "\n",
    "    return f1_score(valid_labels, valid_preds, average='samples', zero_division=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]: 100%|██████████| 230/230 [00:05<00:00, 44.89it/s, train_loss=0.07201, train_f1=0.20455, valid_f1=0.38887]\n",
      "Epoch [2/30]: 100%|██████████| 230/230 [00:04<00:00, 49.11it/s, train_loss=0.03594, train_f1=0.43168, valid_f1=0.41287]\n",
      "Epoch [3/30]: 100%|██████████| 230/230 [00:04<00:00, 48.96it/s, train_loss=0.02987, train_f1=0.46858, valid_f1=0.45955]\n",
      "Epoch [4/30]: 100%|██████████| 230/230 [00:04<00:00, 48.84it/s, train_loss=0.01681, train_f1=0.61256, valid_f1=0.66538]\n",
      "Epoch [5/30]: 100%|██████████| 230/230 [00:04<00:00, 48.96it/s, train_loss=0.00909, train_f1=0.78543, valid_f1=0.78769]\n",
      "Epoch [6/30]: 100%|██████████| 230/230 [00:04<00:00, 50.14it/s, train_loss=0.00619, train_f1=0.86694, valid_f1=0.83016]\n",
      "Epoch [7/30]: 100%|██████████| 230/230 [00:04<00:00, 47.93it/s, train_loss=0.00483, train_f1=0.90145, valid_f1=0.86037]\n",
      "Epoch [8/30]: 100%|██████████| 230/230 [00:04<00:00, 48.11it/s, train_loss=0.00400, train_f1=0.92178, valid_f1=0.87302]\n",
      "Epoch [9/30]: 100%|██████████| 230/230 [00:04<00:00, 47.89it/s, train_loss=0.00348, train_f1=0.93308, valid_f1=0.87079]\n",
      "Epoch [10/30]: 100%|██████████| 230/230 [00:04<00:00, 49.58it/s, train_loss=0.00310, train_f1=0.94012, valid_f1=0.87757]\n",
      "Epoch [11/30]: 100%|██████████| 230/230 [00:04<00:00, 48.04it/s, train_loss=0.00286, train_f1=0.94723, valid_f1=0.87724]\n",
      "Epoch [12/30]: 100%|██████████| 230/230 [00:04<00:00, 49.04it/s, train_loss=0.00254, train_f1=0.95155, valid_f1=0.88224]\n",
      "Epoch [13/30]: 100%|██████████| 230/230 [00:04<00:00, 48.98it/s, train_loss=0.00243, train_f1=0.95388, valid_f1=0.88680]\n",
      "Epoch [14/30]: 100%|██████████| 230/230 [00:04<00:00, 49.97it/s, train_loss=0.00224, train_f1=0.95692, valid_f1=0.88266]\n",
      "Epoch [15/30]: 100%|██████████| 230/230 [00:04<00:00, 49.92it/s, train_loss=0.00214, train_f1=0.95827, valid_f1=0.88805]\n",
      "Epoch [16/30]: 100%|██████████| 230/230 [00:04<00:00, 48.22it/s, train_loss=0.00204, train_f1=0.96001, valid_f1=0.88994]\n",
      "Epoch [17/30]: 100%|██████████| 230/230 [00:04<00:00, 48.86it/s, train_loss=0.00191, train_f1=0.96261, valid_f1=0.88012]\n",
      "Epoch [18/30]: 100%|██████████| 230/230 [00:04<00:00, 48.92it/s, train_loss=0.00184, train_f1=0.96384, valid_f1=0.87986]\n",
      "Epoch [19/30]: 100%|██████████| 230/230 [00:04<00:00, 50.04it/s, train_loss=0.00178, train_f1=0.96451, valid_f1=0.88807]\n",
      "Epoch [20/30]: 100%|██████████| 230/230 [00:04<00:00, 49.16it/s, train_loss=0.00168, train_f1=0.96621, valid_f1=0.88853]\n",
      "Epoch [21/30]: 100%|██████████| 230/230 [00:04<00:00, 49.91it/s, train_loss=0.00161, train_f1=0.96734, valid_f1=0.88808]\n",
      "Epoch [22/30]: 100%|██████████| 230/230 [00:04<00:00, 47.93it/s, train_loss=0.00157, train_f1=0.96820, valid_f1=0.89324]\n",
      "Epoch [23/30]: 100%|██████████| 230/230 [00:04<00:00, 49.94it/s, train_loss=0.00154, train_f1=0.96831, valid_f1=0.89294]\n",
      "Epoch [24/30]: 100%|██████████| 230/230 [00:04<00:00, 48.88it/s, train_loss=0.00147, train_f1=0.96862, valid_f1=0.89369]\n",
      "Epoch [25/30]: 100%|██████████| 230/230 [00:04<00:00, 49.23it/s, train_loss=0.00138, train_f1=0.97162, valid_f1=0.89126]\n",
      "Epoch [26/30]: 100%|██████████| 230/230 [00:04<00:00, 49.66it/s, train_loss=0.00135, train_f1=0.97118, valid_f1=0.89655]\n",
      "Epoch [27/30]: 100%|██████████| 230/230 [00:04<00:00, 47.28it/s, train_loss=0.00133, train_f1=0.97112, valid_f1=0.88508]\n",
      "Epoch [28/30]: 100%|██████████| 230/230 [00:04<00:00, 47.98it/s, train_loss=0.00131, train_f1=0.97195, valid_f1=0.89189]\n",
      "Epoch [29/30]: 100%|██████████| 230/230 [00:04<00:00, 49.77it/s, train_loss=0.00124, train_f1=0.97295, valid_f1=0.88810]\n",
      "Epoch [30/30]: 100%|██████████| 230/230 [00:04<00:00, 47.95it/s, train_loss=0.00122, train_f1=0.97277, valid_f1=0.89365]\n"
     ]
    }
   ],
   "source": [
    "epoch_size = 30\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "\n",
    "model = AuthorAttriClf().to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optim, lr_lambda=lambda epoch: 0.96)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "train_status = {'train_loss': []}\n",
    "train(train_status, model, optim, scheduler, criterion, epoch_size, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json(r'data/backup/test.json')\n",
    "\n",
    "pred_ids = []\n",
    "for i in df_test['identifier']:\n",
    "    pred_ids.append(i)\n",
    "pred_ids = np.array(pred_ids)\n",
    "\n",
    "data_test = []\n",
    "for _, row in df_test.iterrows():\n",
    "    text = [str(i) for i in row['title']]\n",
    "    text.extend([str(i) for i in row['abstract']])\n",
    "    text = d2v.infer_vector(text)\n",
    "    \n",
    "    coauthors = np.zeros(21146)\n",
    "    coauthors[[i-100 for i in [i for i in row['coauthors'] if i >= 100]]] = 1.\n",
    "    \n",
    "    venue = np.zeros(465)\n",
    "    venue[[row['venue']] if row['venue'] != '' else []] = 1.\n",
    "    \n",
    "    data_test.append(np.concatenate([text, coauthors, venue], axis=0))\n",
    "    \n",
    "data_test = np.stack(data_test)\n",
    "\n",
    "test_set = TensorDataset(torch.tensor(data_test, dtype=torch.float), torch.tensor(pred_ids, dtype=torch.float))\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2x3VIck3495a"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        identifiers = []\n",
    "\n",
    "        for batch, (inputs, ids) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "            for i in range(outputs.shape[0]):\n",
    "                identifiers.append(int(ids[i]))\n",
    "                pred = torch.nonzero((outputs[i].cpu() > 0.5)[:-1].int())\n",
    "                if len(pred) > 0:\n",
    "                    preds.append(\" \".join([str(int(i)) for i in pred]))\n",
    "                else:\n",
    "                    preds.append(\"-1\")\n",
    "        df = pd.DataFrame({'ID': identifiers, 'Predict': preds})\n",
    "        df.to_csv(r'data/pred.csv', sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "get_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
