{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6g8VdHBne1jz",
    "outputId": "2b8f632a-6a0d-45c1-b201-7d84024916c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.63.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gensim==4.2.0 in /opt/conda/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.7.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (6.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.21.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install sklearn\n",
    "!pip install gensim==4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JbkGG-nlmzSI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nm169Kxtd-bV"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6fZS7S0PvhHh",
    "outputId": "8bf1da1b-1f4f-4d30-88fe-10c928052cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct  7 05:31:21 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 30%   31C    P8    19W / 350W |      3MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proauthors(row):\n",
    "    return [i for i in row['authors'] if i < 100]\n",
    "\n",
    "def get_coauthors(row):\n",
    "    return [i for i in row['authors'] if i >= 100]\n",
    "\n",
    "def has_proauthors(row):\n",
    "    if len(row['proauthors']) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = json.load(open(r'data/backup/train.json'))\n",
    "df = pd.read_json(r'data/backup/train.json')\n",
    "df['proauthors'] = df.apply(lambda row: get_proauthors(row), axis=1)\n",
    "df['coauthors'] = df.apply(lambda row: get_coauthors(row), axis=1)\n",
    "df['has_proauthors'] = df.apply(lambda row: has_proauthors(row), axis=1)\n",
    "df_f = df[df['has_proauthors']==False]\n",
    "df_t = df[df['has_proauthors']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = resample(df_t, replace=True, n_samples=int(len(df_f)), random_state=90051)\n",
    "# df_f = resample(df_f, replace=True, n_samples=int((1/3)*len(df_t)), random_state=90051)\n",
    "df = pd.concat([df_t, df_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for ids in df['proauthors']:\n",
    "    label = np.zeros(101)\n",
    "    if len(ids) > 0:\n",
    "        label[ids] = 1.\n",
    "    else:\n",
    "        label[-1] = 1.\n",
    "    labels.append(label)\n",
    "    \n",
    "labels = np.stack(labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "10000\n",
      "0\n",
      "10000\n",
      "10000\n",
      "0\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "d2v = gensim.models.doc2vec.Doc2Vec.load(r'doc2vec.model')\n",
    "\n",
    "for row in df.itertuples():\n",
    "    if (row.Index%10000==0):\n",
    "        print(row.Index)\n",
    "        \n",
    "    text = [str(i) for i in row.title]\n",
    "    text.extend([str(i) for i in row.abstract])\n",
    "    text =d2v.infer_vector(text)\n",
    "    \n",
    "    coauthors = np.zeros(21146)\n",
    "    coauthors[[i-100 for i in row.coauthors]] = 1.\n",
    "    \n",
    "    venue = np.zeros(465)\n",
    "    venue[[row.venue] if row.venue != '' else []] = 1.\n",
    "    \n",
    "    data.append(np.concatenate([text, coauthors, venue], axis=0))\n",
    "    \n",
    "data = np.stack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36666, 21867)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36666, 101)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid, labels_train, labels_valid = train_test_split(data, labels, test_size=0.2, random_state=90051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(torch.tensor(data_train, dtype=torch.float), torch.tensor(labels_train, dtype=torch.float))\n",
    "valid_set = TensorDataset(torch.tensor(data_valid, dtype=torch.float), torch.tensor(labels_valid, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UqCD9F1lIGGv"
   },
   "outputs": [],
   "source": [
    "class AuthorAttriClf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AuthorAttriClf, self).__init__()\n",
    "        \n",
    "        self.clf_block = nn.Sequential(\n",
    "            nn.Linear(21867, 2048),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 101),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        probs = self.clf_block(input)\n",
    "\n",
    "        return probs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qTd7tZgJO-tz"
   },
   "outputs": [],
   "source": [
    "def train(train_status, model, optim, scheduler, criterion, epoch_size, train_loader, valid_loader):\n",
    "   \n",
    "    for epoch in range(epoch_size):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_labels = torch.Tensor([])\n",
    "        epoch_preds = torch.Tensor([])\n",
    "\n",
    "        train_loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        train_loop.set_description(f\"Epoch [{epoch+1}/{epoch_size}]\")\n",
    "\n",
    "        for batch, (inputs, labels) in train_loop:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step() \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_preds = torch.cat(((epoch_preds, (outputs.detach().cpu() > 0.5).int())), 0)\n",
    "            epoch_labels = torch.cat((epoch_labels, labels.detach().cpu()), 0)\n",
    "\n",
    "            train_loop.set_postfix_str(\n",
    "                'train_loss={:.5f}'.format(loss.item())\n",
    "            )\n",
    "\n",
    "            if batch == len(train_loader)-1:\n",
    "                epoch_loss /= len(train_loader.dataset)/train_loader.batch_size\n",
    "                train_f1 = f1_score(epoch_labels, epoch_preds, average='samples', zero_division=1)\n",
    "                valid_f1 = validate(model, valid_loader)\n",
    "                train_loop.set_postfix_str(\n",
    "                    'train_loss={:.5f}, train_f1={:.5f}, valid_f1={:.5f}'.format(\n",
    "                        epoch_loss, train_f1, valid_f1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "def validate(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_labels = torch.Tensor([])\n",
    "    valid_preds = torch.Tensor([])\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            valid_preds = torch.cat(((valid_preds, (outputs.detach().cpu() > 0.5).int())), 0)\n",
    "            valid_labels = torch.cat((valid_labels, labels.detach().cpu()), 0)\n",
    "\n",
    "    return f1_score(valid_labels, valid_preds, average='samples', zero_division=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]: 100%|██████████| 917/917 [00:14<00:00, 63.22it/s, train_loss=0.05268, train_f1=0.33895, valid_f1=0.43608]\n",
      "Epoch [2/50]: 100%|██████████| 917/917 [00:14<00:00, 61.77it/s, train_loss=0.02194, train_f1=0.63306, valid_f1=0.69020]\n",
      "Epoch [3/50]: 100%|██████████| 917/917 [00:14<00:00, 62.31it/s, train_loss=0.01384, train_f1=0.77896, valid_f1=0.73232]\n",
      "Epoch [4/50]: 100%|██████████| 917/917 [00:14<00:00, 63.73it/s, train_loss=0.01126, train_f1=0.82909, valid_f1=0.80795]\n",
      "Epoch [5/50]: 100%|██████████| 917/917 [00:14<00:00, 63.71it/s, train_loss=0.01051, train_f1=0.85434, valid_f1=0.79391]\n",
      "Epoch [6/50]:  94%|█████████▍| 866/917 [00:12<00:00, 60.37it/s, train_loss=0.00678]"
     ]
    }
   ],
   "source": [
    "epoch_size = 50\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "\n",
    "model = AuthorAttriClf().to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optim, lr_lambda=lambda epoch: 0.96)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "train_status = {'train_loss': []}\n",
    "train(train_status, model, optim, scheduler, criterion, epoch_size, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json(r'data/backup/test.json')\n",
    "\n",
    "pred_ids = []\n",
    "for i in df_test['identifier']:\n",
    "    pred_ids.append(i)\n",
    "pred_ids = np.array(pred_ids)\n",
    "\n",
    "data_test = []\n",
    "for _, row in df_test.iterrows():\n",
    "    text = [str(i) for i in row['title']]\n",
    "    text.extend([str(i) for i in row['abstract']])\n",
    "    text =d2v.infer_vector(text)\n",
    "    \n",
    "    coauthors = np.zeros(21146)\n",
    "    coauthors[[i-100 for i in row['coauthors']]] = 1.\n",
    "    \n",
    "    venue = np.zeros(465)\n",
    "    venue[[row['venue']] if row['venue'] != '' else []] = 1.\n",
    "    \n",
    "    data_test.append(np.concatenate([text, coauthors, venue], axis=0))\n",
    "data_test = np.stack(data_test)\n",
    "\n",
    "test_set = TensorDataset(torch.tensor(data_test, dtype=torch.float), torch.tensor(pred_ids, dtype=torch.float))\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2x3VIck3495a"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, test_loader, FILENAME=\"/content/gdrive/MyDrive/Colab Notebooks/COMP90051/Project2/data/pred.csv\"):\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        identifiers = []\n",
    "\n",
    "        for batch, (inputs, ids) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "            for i in range(outputs.shape[0]):\n",
    "                identifiers.append(int(ids[i]))\n",
    "                pred = torch.nonzero((outputs[i].cpu() > 0.5).int())\n",
    "                if len(pred[:-1]) > 0:\n",
    "                    preds.append(\" \".join([str(int(i)) for i in pred[:-1]]))\n",
    "                else:\n",
    "                    preds.append(\"-1\")\n",
    "\n",
    "        df = pd.DataFrame({'ID': identifiers, 'Predict': preds})\n",
    "        df.to_csv(r'data/pred.csv', sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "get_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
